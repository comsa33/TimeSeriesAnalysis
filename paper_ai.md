# 인공지능(AI) 연구의 주요 논문

---

### **1️⃣ 머신러닝 및 딥러닝 기초 논문**
| 논문 제목 | 저자 | 연도 | 주요 내용 | 링크 |
|----------|------|------|---------|------|
| **The Elements of Statistical Learning** | Hastie, Tibshirani, Friedman | 2001 | 머신러닝의 기본 개념과 방법론 정리 | [🔗 Link](https://web.stanford.edu/~hastie/ElemStatLearn/) |
| **Pattern Recognition and Machine Learning** | Christopher M. Bishop | 2006 | 머신러닝 이론의 기초가 되는 책 | [🔗 Link](https://www.springer.com/gp/book/9780387310732) |
| **A Few Useful Things to Know About Machine Learning** | Pedro Domingos | 2012 | 머신러닝에서 흔히 간과되는 개념과 원칙 소개 | [🔗 Link](https://dl.acm.org/doi/10.1145/2347736.2347755) |

---

### **2️⃣ 신경망 및 딥러닝 기초 논문**
| 논문 제목 | 저자 | 연도 | 주요 내용 | 링크 |
|----------|------|------|---------|------|
| **Backpropagation Applied to Handwritten Zip Code Recognition** | Yann LeCun et al. | 1989 | CNN(합성곱 신경망)의 기초 개념을 확립한 논문 | [🔗 Link](https://www.researchgate.net/publication/243767918_Backpropagation_applied_to_handwritten_zip_code_recognition) |
| **Gradient-Based Learning Applied to Document Recognition** | Yann LeCun et al. | 1998 | CNN을 활용한 문서 인식 모델 | [🔗 Link](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) |
| **Learning Representations by Backpropagating Errors** | Rumelhart, Hinton & Williams | 1986 | 역전파(Backpropagation) 알고리즘 소개 | [🔗 Link](https://www.nature.com/articles/323533a0) |
| **Understanding Deep Learning Requires Rethinking Generalization** | Zhang et al. | 2017 | 딥러닝 모델의 일반화 문제 탐구 | [🔗 Link](https://arxiv.org/abs/1611.03530) |

---

### **3️⃣ CNN (합성곱 신경망) 및 이미지 인식**
| 논문 제목 | 저자 | 연도 | 주요 내용 | 링크 |
|----------|------|------|---------|------|
| **ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)** | Krizhevsky, Sutskever, Hinton | 2012 | ImageNet 대회에서 CNN의 성능을 입증한 논문 | [🔗 Link](https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) |
| **Very Deep Convolutional Networks for Large-Scale Image Recognition (VGGNet)** | Simonyan & Zisserman | 2014 | VGG 네트워크 구조 제안 | [🔗 Link](https://arxiv.org/abs/1409.1556) |
| **Deep Residual Learning for Image Recognition (ResNet)** | He, Zhang, Ren & Sun | 2015 | Residual Network (ResNet) 구조 제안 | [🔗 Link](https://arxiv.org/abs/1512.03385) |

---

### **4️⃣ RNN, LSTM 및 NLP (자연어 처리)**
| 논문 제목 | 저자 | 연도 | 주요 내용 | 링크 |
|----------|------|------|---------|------|
| **Long Short-Term Memory (LSTM)** | Hochreiter & Schmidhuber | 1997 | LSTM 알고리즘 제안 | [🔗 Link](https://www.bioinf.jku.at/publications/older/2604.pdf) |
| **Sequence to Sequence Learning with Neural Networks** | Sutskever, Vinyals, Le | 2014 | Seq2Seq 모델 제안 (기계 번역에서 사용) | [🔗 Link](https://arxiv.org/abs/1409.3215) |
| **Attention Is All You Need (Transformer)** | Vaswani et al. | 2017 | 트랜스포머(Transformer) 모델 제안 | [🔗 Link](https://arxiv.org/abs/1706.03762) |
| **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding** | Devlin et al. | 2018 | BERT 모델 제안 | [🔗 Link](https://arxiv.org/abs/1810.04805) |

---

### **5️⃣ 강화학습 및 AI 전략**
| 논문 제목 | 저자 | 연도 | 주요 내용 | 링크 |
|----------|------|------|---------|------|
| **Playing Atari with Deep Reinforcement Learning (DQN)** | Mnih et al. | 2013 | 딥 Q-러닝(DQN) 소개 | [🔗 Link](https://arxiv.org/abs/1312.5602) |
| **Mastering the Game of Go with Deep Neural Networks and Tree Search (AlphaGo)** | Silver et al. | 2016 | AlphaGo의 작동 원리 | [🔗 Link](https://www.nature.com/articles/nature16961) |
| **Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm (AlphaZero)** | Silver et al. | 2017 | AlphaZero의 자기 학습 강화학습 방법 | [🔗 Link](https://arxiv.org/abs/1712.01815) |

---

### **6️⃣ 생성 모델 (GAN, VAE, Diffusion)**
| 논문 제목 | 저자 | 연도 | 주요 내용 | 링크 |
|----------|------|------|---------|------|
| **Generative Adversarial Networks (GANs)** | Goodfellow et al. | 2014 | GAN 모델 제안 | [🔗 Link](https://arxiv.org/abs/1406.2661) |
| **Auto-Encoding Variational Bayes (VAE)** | Kingma & Welling | 2013 | VAE(변분 오토인코더) 제안 | [🔗 Link](https://arxiv.org/abs/1312.6114) |
| **Denoising Diffusion Probabilistic Models (DDPM)** | Ho et al. | 2020 | Diffusion 모델 제안 | [🔗 Link](https://arxiv.org/abs/2006.11239) |

---

### **7️⃣ 대형 언어 모델 및 최신 AI**
| 논문 제목 | 저자 | 연도 | 주요 내용 | 링크 |
|----------|------|------|---------|------|
| **Scaling Laws for Neural Language Models** | Kaplan et al. | 2020 | 신경망 크기와 성능의 관계 분석 | [🔗 Link](https://arxiv.org/abs/2001.08361) |
| **GPT-3: Language Models are Few-Shot Learners** | Brown et al. | 2020 | GPT-3 모델 소개 | [🔗 Link](https://arxiv.org/abs/2005.14165) |
| **PaLM: Scaling Language Models with Pathways** | Chowdhery et al. | 2022 | Google의 대형 언어 모델 PaLM | [🔗 Link](https://arxiv.org/abs/2204.02311) |
| **GPT-4 Technical Report** | OpenAI | 2023 | GPT-4 모델 소개 | [🔗 Link](https://arxiv.org/abs/2303.08774) |

---

